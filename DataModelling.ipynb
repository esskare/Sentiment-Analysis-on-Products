{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.12.3)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print (f\"Feature names: {data.columns.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the record where 'verified_reviews ' is null\n",
    "data[data['Reviews'].isna() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping null record\n",
    "data.dropna(inplace = True)\n",
    "#dataset after dropping null valus\n",
    "print(f\"Dataset shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column 'length' that will contain the length of the string in 'verified_reviews\" column\n",
    "data['length'] = data['Reviews'].apply(len)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"'Reviews' column value: {data.iloc[10]['Reviews']}\") #Original value\n",
    "print(f\"Length of Review: {len(data.iloc[10]['Reviews'])}\") #Length of review using len()\",\n",
    "print(f\"'length' column value : {data.iloc[10]['length']}\") #Value of the column 'length'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYZING THE RATING COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISTINCT VALUES OF 'RATING' AND ITS COUNT\n",
    "print(f\"Rating value count: \\n{data['Rating'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar plots to visualize the total count of each rating\n",
    "import matplotlib.pyplot as plt\n",
    "data['Rating'].value_counts().plot.bar(color = 'blue')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Total count of each rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the percentage distribution of each rating - we'll divide the number of records for each rating by total number of records\\n\",\n",
    "print(f\"Rating value count - percentage distribution: \\\\n{round(data['Rating'].value_counts()/data.shape[0]*100,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "# Define colors and wedge properties\n",
    "colors = ['red', 'green']\n",
    "wp = {'linewidth': 1, \"edgecolor\": 'black'}\n",
    "\n",
    "# Calculate the proportion of each feedback type\n",
    "tags = data['Review Votes'].value_counts() / data.shape[0]\n",
    "\n",
    "# Ensure explode matches the length of tags\n",
    "explode = [0.1] * len(tags)\n",
    "\n",
    "# Define labels to match the unique values in 'Review Votes' (assuming 0=Negative and 1=Positive)\n",
    "\n",
    "\n",
    "# Plot the pie chart\n",
    "tags.plot(kind='pie', autopct=\"%1.1f%%\", shadow=True, colors=colors,\n",
    "          startangle=90, wedgeprops=wp, explode=explode)\n",
    "\n",
    "# Set title\n",
    "plt.title('Percentage-wise distribution of Review Votes')\n",
    "plt.ylabel('')  # Optional: remove the default y-axis label\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYZING FEEDBACK COLUMN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Distinct values of 'feedback' and its count\n",
    "print(f\"Feedback value count: \\n{data['Review Votes'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the 'verified_reviews' value for one record with feedback = 0\n",
    "review_1 = data[data['Review Votes'] == 0].iloc[1]['Reviews']\n",
    "print(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the 'verified_reviews' value for one record with feedback = 1\n",
    "review_0 = data[data['Review Votes'] == 1].iloc[1]['Reviews']\n",
    "print(review_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar graph to visualize the total counts of each feedback\n",
    "data['Review Votes Binned'] = pd.cut(data['Review Votes'], bins=[0, 5, 10, 20])\n",
    "data['Review Votes Binned'].value_counts().sort_index().plot.bar(color='red')\n",
    "\n",
    "plt.xlabel('Review Votes')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Total count of each Review Votes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the percentage distribution of each feedback - we'll divide the number of records for each feedback by total number of records\n",
    "print(f\"Feedback value count - percentage distribution: \\n{round(data['Review Votes'].value_counts()/data.shape[0]*100,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'tags' has been defined as in your code\n",
    "num_tags = len(tags)\n",
    "\n",
    "# Adjust explode to match the number of tags\n",
    "explode = (0.1,) * num_tags  # This will create a tuple of the correct length\n",
    "\n",
    "# Plotting\n",
    "tags.plot(kind='pie', autopct=\"%1.1f%%\", shadow=True, colors=colors,\n",
    "          startangle=90, wedgeprops=wp, explode=explode)\n",
    "\n",
    "plt.title('Percentage-wise Distribution of Feedback')\n",
    "plt.ylabel('')  # Hides the y-label\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feedback = 0\n",
    "data[data['Review Votes'] == 0]['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feedback = 1\n",
    "data[data['Review Votes'] == 1]['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYZING VARIATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DISTINCT VALUES OF 'VARIATION' AND ITS COUNT\n",
    "print(f\"Variation value count: \\n {data['Brand Name'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the top 50 brands by count in a bar chart\n",
    "data['Brand Name'].value_counts().head().plot.bar(color='red')\n",
    "plt.xlabel('Brand Name')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Top 30 Brands by Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the percentage distribution of each variation - we'll divide the number of records for each variation by total number of records\n",
    "print(f\"Variation value count - percentage distribution: \\n{round(data['Brand Name'].value_counts()/data.shape[0]*100,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Brand Name')['Rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Brand Name')['Rating'].mean().sort_values().plot.bar(color = 'brown', figsize=(11, 6))\n",
    "plt.title(\"Mean rating according to variation\")\n",
    "plt.xlabel('Brand Name')\n",
    "plt.ylabel('Mean rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['length'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data['length'],color='blue').set(title='Distribution of length of review ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data[data['Review Votes']==0]['length'],color='red').set(title='Distribution of length of review if feedback = 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data[data['Review Votes']==1]['length'],color='green').set(title='Distribution of length of review if feedback = 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('length')['Rating'].mean().plot.hist(color = 'blue', figsize=(7, 6), bins = 20)\n",
    "plt.title(\" Review length wise mean ratings\")\n",
    "plt.xlabel('Ratings')\n",
    "plt.ylabel('length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "words = cv.fit_transform(data.Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all reviews\n",
    "all_reviews = ' '.join(data['Reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wordcloud object\n",
    "wordcloud = WordCloud(max_words=50, background_color='white')\n",
    "# Generate and plot wordcloud\n",
    "wordcloud.generate(all_reviews)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Wordcloud for all reviews', fontsize=10)\n",
    "plt.imshow(wordcloud.generate(all_reviews))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding Unique words i each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all reviews for each feedback category and splitting them into individual words\n",
    "positive_reviews = ' '.join(data[data['Review Votes'] == 1]['Reviews']).split()\n",
    "\n",
    "negative_reviews = ' '.join(data[data['Review Votes'] == 0]['Reviews']).split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding words from reviews which are present in that feedback category only\n",
    "unique_positive_words = [word for word in positive_reviews if word not in negative_reviews]\n",
    "unique_positive = \" \".join(unique_positive_words)\n",
    "\n",
    "unique_negative_words = [word for word in negative_reviews if word not in positive_reviews]\n",
    "unique_negative = \" \".join(unique_negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color='white', max_words=50)\n",
    "\n",
    "# Generate and plot wordcloud\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Wordcloud for negative reviews', fontsize=10)\n",
    "plt.imshow(wordcloud.generate(unique_negative))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "negative words can be found above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color='white', max_words=50)\n",
    "\n",
    "# Generate and plot wordcloud\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Wordcloud for positive reviews', fontsize=10)\n",
    "plt.imshow(wordcloud.generate(unique_positive))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "postove words can be found above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING AND MODELLING\n",
    "- To build the corpus from the 'Reviews' we perform the following :\n",
    " 1. Replace any non alphabet characters with a space\n",
    " 2. Covert to lower case and split into words \n",
    " 3. Iterate over the individual words and if it is not a stopword then add the stemmed form of the word to the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corpus = []\n",
    "stemmer = PorterStemmer()\n",
    "for i in range(0, data.shape[0]):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', data.iloc[i]['Reviews'])\n",
    "    review = review.lower().split()\n",
    "    review = [stemmer.stem(word) for word in review if word not in STOPWORDS]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Count Vectorizer to create bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features = 2500)\n",
    "\n",
    "#Storing independent and dependent variables in X and y\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = data['Review Votes'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking X and Y shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the Count Vectorizer\n",
    "pickle.dump(cv, open('Models/countVectorizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking x and y shape\n",
    "print(f\"X shape {X.shape}\")\n",
    "print(f\"Y shape {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Splitting data into train and test set with 30% data with testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 15)\n",
    "print(f\"X train: {X_train.shape}\")\n",
    "print(f\"y train: {y_train.shape}\")\n",
    "print(f\"X test: {X_test.shape}\")\n",
    "print(f\"y test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X train max value: {X_train.max()}\")\n",
    "print(f\"X test max value: {X_test.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scl = scaler.fit_transform(X_train)\n",
    "X_test_scl = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the scaler model\n",
    "pickle.dump(scaler, open('Models/scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Fitting scaled X_train and y_train on Random Forest Classifier\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train_scl, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy of the model on training and testing data\n",
    "\n",
    "print(\"Training Accuracy :\", model_rf.score(X_train_scl, y_train))\n",
    "print(\"Testing Accuracy :\", model_rf.score(X_test_scl, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting on the test set\n",
    "y_preds = model_rf.predict(X_test_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
